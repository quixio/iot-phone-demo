# Global Agent Configuration
[agent]
  interval = "10s"
  round_interval = true
  metric_batch_size = 1000
  metric_buffer_limit = 10000
  collection_jitter = "0s"
  flush_interval = "1s"
  flush_jitter = "0s"
  precision = ""
  debug = false
  quiet = false
  logfile = ""

# Input Plugin: HTTP Listener v2
[[inputs.http_listener_v2]]
  service_address = ":80"
  path = "/telegraf"
  methods = ["POST"]
  data_format = "json_v2" 

  [[inputs.http_listener_v2.json_v2]]
    measurement_name = "raw_payload"  # Sets the measurement name for metrics
    # Uncomment and configure the following options if needed
    # timestamp_key = "timestamp"  # Optional, specify a JSON field as timestamp
    # timestamp_format = "unix_ms" # Optional, format of the timestamp
    # tag_keys = ["device_id"]     # Optional, specify JSON fields to use as tags
    # field_key = "value"          # Optional, specify JSON fields to use as fields

# Processor Plugin: Starlark to set the kafka_key
[[processors.starlark]]
  source = '''
def apply(metric):
    if "device_id" in metric.fields:
        metric.tags["kafka_key"] = str(metric.fields["device_id"])
    return metric
  '''

# Output Plugin: Kafka
[[outputs.kafka]]
  brokers = [
    "kafka-k1.quix.io:9093",
    "kafka-k2.quix.io:9093",
    "kafka-k3.quix.io:9093"
  ]
  topic = "${Quix__Workspace__Id}-${OUTPUT_TOPIC}"
  data_format = "json"
  kafka_key = "kafka_key"   # Use "kafka_key" tag as the message key

  # SASL Authentication Settings

  sasl_username = "${KAFKA_SASL_USERNAME}"
  sasl_password = "${KAFKA_SASL_PASSWORD}"
  sasl_mechanism = "${KAFKA_SASL_MECHANISM}"

  # Security Protocol
  #security_protocol = "SASL_SSL"

  ## Optional TLS Config
  enable_tls = true
  tls_ca = "/etc/ssl/certs/ca.pem" 
  insecure_skip_verify = false